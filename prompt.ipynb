{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt_str = \"\"\"\n",
    "    根据给定的上下文信息回答问题。\n",
    "    上下文信息如下：\n",
    "    ---------------------\n",
    "    {context_str}\n",
    "    ---------------------\n",
    "    根据上述上下文信息，不考虑之前的任何知识，回答以下问题：\n",
    "    {query_str}\n",
    "    \"\"\"\n",
    "\n",
    "refine_prompt_str = \"\"\"我们有机会对原始答案进行细化 （仅在有需要时）下面提供更多上下文。\n",
    "\n",
    "    {context_msg}\n",
    "    考虑到新的上下文，请细化原始答案以更好地回答问题：{query_str}。 如果上下文没有帮助，请再次输出原始答案。\n",
    "\n",
    "    原始答案：{existing_answer}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage,MessageRole\n",
    "from llama_index.core import ChatPromptTemplate\n",
    "\n",
    "chat_text_qa_msgs = [\n",
    "    ChatMessage(\n",
    "        role=MessageRole.SYSTEM,\n",
    "        content=(\"\"\"即使在上下文没有帮助的情况下，也回答问题。\"\"\")\n",
    "        ),\n",
    "    ChatMessage(\n",
    "        role=MessageRole.USER,\n",
    "        content=qa_prompt_str)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_text_qa_template = ChatPromptTemplate(chat_text_qa_msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(metadata={'prompt_type': <PromptType.CUSTOM: 'custom'>}, template_vars=['context_str', 'query_str'], kwargs={}, output_parser=None, template_var_mappings=None, function_mappings=None, message_templates=[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content='即使在上下文没有帮助的情况下，也回答问题。', additional_kwargs={}), ChatMessage(role=<MessageRole.USER: 'user'>, content='\\n    根据给定的上下文信息回答问题。\\n    上下文信息如下：\\n    ---------------------\\n    {context_str}\\n    ---------------------\\n    根据上述上下文信息，不考虑之前的任何知识，回答以下问题：\\n    {query_str}\\n    ', additional_kwargs={})])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_text_qa_template"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
